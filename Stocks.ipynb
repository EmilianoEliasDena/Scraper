{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6aca235",
   "metadata": {},
   "source": [
    "'scraper.py' is a Python module that defines my own personal 'Scraper class'. This class has the following methods:\n",
    "\n",
    "    'init': This is the constructor method that is called when an instance of the Scraper class is created. It takes the URL of the page to scrape (SOURCE: Wikipedia) and the API key for the Alpha Vantage API as arguments, and initializes the following instance variables:\n",
    "\n",
    "    'self.url': The URL of the page to scrape\n",
    "    'self.api_key': The API key for the Alpha Vantage API\n",
    "    'self.base_url': The base URL for the Alpha Vantage API\n",
    "\n",
    "    'parse_page': This method fetches the HTML content of the page at the URL specified in the 'self.url' instance variable, and parses it using the 'BeautifulSoup' library. It returns the 'BeautifulSoup' object representing the parsed HTML.\n",
    "\n",
    "    'parse_table': This method takes the 'BeautifulSoup' object returned by 'parse_page' as an argument, and uses it to find the table on the page that you want to scrape. It then uses the pandas library to read the table data into a DataFrame and return it.\n",
    "\n",
    "    'get_overview': This method makes a GET request to the Alpha Vantage API to get overview data for a given symbol. It takes the symbol as an argument, constructs the URL for the request using the 'self.base_url' and 'self.api_key' instance variables, and makes the request using the 'requests' library. It returns the response from the API as a dictionary.\n",
    "\n",
    "    'get_data': This method iterates over the symbols in the 'self.df' DataFrame and calls 'get_overview' for each symbol to get the overview data. It appends the overview data to a new DataFrame called data and returns it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3e5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraper.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, url, api_key):\n",
    "        \"\"\"\n",
    "        Initialize the scraper object with the URL of the page to scrape\n",
    "        and the API key for the Alpha Vantage API.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.api_url = \"https://www.alphavantage.co/query\"\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        # Fetch the page and parse the table\n",
    "        self.soup = self.fetch_page()\n",
    "        self.df = self.parse_table(\"Symbol\")\n",
    "\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"\n",
    "        Fetch the HTML content of the page using the requests library.\n",
    "        Return the BeautifulSoup object containing the parsed HTML.\n",
    "        \"\"\"\n",
    "        # Use the requests library to fetch the HTML content of the page\n",
    "        try:\n",
    "            with requests.get(self.url) as r:\n",
    "                r.raise_for_status()\n",
    "                soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise Exception(\"Error: Could not fetch the page\") from e\n",
    "\n",
    "        return soup\n",
    "\n",
    "    def parse_table(self, index_col):\n",
    "        \"\"\"\n",
    "        Use the `pandas` library to read the table from the HTML.\n",
    "        Return the parsed table as a DataFrame.\n",
    "        \"\"\"\n",
    "        # Find the table on the page using its attributes\n",
    "        table = self.soup.find(\"table\", attrs={\"class\": \"wikitable sortable\"})\n",
    "\n",
    "        # Check if the table was found\n",
    "        if table is None:\n",
    "            raise Exception(\"Error: Invalid table number\")\n",
    "\n",
    "        # Parse the table using `pandas`\n",
    "        df = pd.read_html(str(table), index_col=\"Symbol\", header=0)[0]\n",
    "\n",
    "        # Return the DataFrame containing the parsed table\n",
    "        return df\n",
    "\n",
    "    def get_overview(self, symbol):\n",
    "        \"\"\"\n",
    "        Make a GET request to the Alpha Vantage API to get overview data for\n",
    "        the given symbol.\n",
    "        \"\"\"\n",
    "        # Set the parameters for the request\n",
    "        params = {\n",
    "            \"function\": \"OVERVIEW\",\n",
    "            \"symbol\": symbol,\n",
    "            \"apikey\": self.api_key\n",
    "        }\n",
    "\n",
    "        # Create the full URL using the base URL and the query string\n",
    "        url = self.api_url + \"?\" + urlencode(params)\n",
    "\n",
    "        # Make a GET request to the API\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            r.raise_for_status()\n",
    "            response = r.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle any errors that occur when making the request\n",
    "            raise Exception(f\"Error: Could not get overview data for symbol {symbol}\") from e\n",
    "        except ValueError as e:\n",
    "            # Handle any errors that occur when parsing the response\n",
    "            raise Exception(f\"Error: Could not parse response for symbol {symbol}\") from e\n",
    "\n",
    "        # Return the response from the API\n",
    "        return response\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Get overview data for each symbol in the `df` DataFrame and append the\n",
    "        data to a new DataFrame called `data`. Add a delay of 12 seconds\n",
    "        between each request to ensure that only 5 requests are made per minute.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create an empty DataFrame to store the data\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        # Iterate over the symbols in the dataframe\n",
    "        for symbol in self.df.index:\n",
    "            # Get the overview data for the symbol\n",
    "            response = self.get_overview(symbol)\n",
    "\n",
    "            # Check if the response contains an error\n",
    "            if \"Error Message\" in response:\n",
    "                raise Exception(f\"Error: {response['Error Message']}\")\n",
    "\n",
    "            # Append the overview data to the DataFrame\n",
    "            data = data.append(response, ignore_index=True)\n",
    "\n",
    "            # Check if there are more than 5 symbols in the DataFrame\n",
    "            if len(self.df.index) > 5:\n",
    "                # Wait 12 seconds before making the next request\n",
    "                time.sleep(12)\n",
    "\n",
    "        # Return the DataFrame containing the overview data\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b5cd24",
   "metadata": {},
   "source": [
    "The following code creates a Scraper object and uses it to scrape a table from the specified URL using the provided API key. The table is then parsed and printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f446d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Company Exchange                        Industry  \\\n",
      "Symbol                                                                      \n",
      "MMM                           3M     NYSE                    Conglomerate   \n",
      "AXP             American Express     NYSE              Financial services   \n",
      "AMGN                       Amgen   NASDAQ               Biopharmaceutical   \n",
      "AAPL                       Apple   NASDAQ          Information technology   \n",
      "BA                        Boeing     NYSE           Aerospace and defense   \n",
      "CAT                  Caterpillar     NYSE         Construction and Mining   \n",
      "CVX                      Chevron     NYSE              Petroleum industry   \n",
      "CSCO                       Cisco   NASDAQ          Information technology   \n",
      "KO                     Coca-Cola     NYSE                  Drink industry   \n",
      "DOW                          Dow     NYSE               Chemical industry   \n",
      "GS                 Goldman Sachs     NYSE              Financial services   \n",
      "HD                    Home Depot     NYSE                Home Improvement   \n",
      "HON                    Honeywell   NASDAQ                    Conglomerate   \n",
      "INTC                       Intel   NASDAQ          Semiconductor industry   \n",
      "IBM                          IBM     NYSE          Information technology   \n",
      "JNJ            Johnson & Johnson     NYSE         Pharmaceutical industry   \n",
      "JPM               JPMorgan Chase     NYSE              Financial services   \n",
      "MCD                   McDonald's     NYSE                   Food industry   \n",
      "MRK                        Merck     NYSE         Pharmaceutical industry   \n",
      "MSFT                   Microsoft   NASDAQ          Information technology   \n",
      "NKE                         Nike     NYSE               Clothing industry   \n",
      "PG              Procter & Gamble     NYSE      Fast-moving consumer goods   \n",
      "CRM                   Salesforce     NYSE          Information technology   \n",
      "TRV                    Travelers     NYSE                       Insurance   \n",
      "UNH                 UnitedHealth     NYSE             Managed health care   \n",
      "VZ                       Verizon     NYSE     Telecommunications industry   \n",
      "V                           Visa     NYSE              Financial services   \n",
      "WBA     Walgreens Boots Alliance   NASDAQ                       Retailing   \n",
      "WMT                      Walmart     NYSE                       Retailing   \n",
      "DIS          Walt Disney Company     NYSE  Broadcasting and entertainment   \n",
      "\n",
      "        Date added                                  Notes Index weighting  \n",
      "Symbol                                                                     \n",
      "MMM     1976-08-09  As Minnesota Mining and Manufacturing           2.41%  \n",
      "AXP     1982-08-30                                    NaN           3.02%  \n",
      "AMGN    2020-08-31                                    NaN           5.48%  \n",
      "AAPL    2015-03-19                                    NaN           2.84%  \n",
      "BA      1987-03-12                                    NaN           3.36%  \n",
      "CAT     1991-05-06                                    NaN           4.52%  \n",
      "CVX     2008-02-19          Also 1930-07-18 to 1999-11-01           3.50%  \n",
      "CSCO    2009-06-08                                    NaN           0.96%  \n",
      "KO      1987-03-12          Also 1932-05-26 to 1935-11-20           1.22%  \n",
      "DOW     1991-05-06                                    NaN           0.98%  \n",
      "GS      2019-04-02                                    NaN           7.36%  \n",
      "HD      1999-11-01                                    NaN           6.27%  \n",
      "HON     2020-08-31             AlliedSignal and Honeywell           4.17%  \n",
      "INTC    1999-11-01                                    NaN           0.57%  \n",
      "IBM     1979-06-29          Also 1932-05-26 to 1939-03-04           2.86%  \n",
      "JNJ     1997-03-17                                    NaN           3.43%  \n",
      "JPM     1991-05-06                                    NaN           2.61%  \n",
      "MCD     1985-10-30                                    NaN           5.24%  \n",
      "MRK     1979-06-29                                    NaN           2.10%  \n",
      "MSFT    1999-11-01                                    NaN           4.88%  \n",
      "NKE     2013-09-20                                    NaN           2.13%  \n",
      "PG      1932-05-26                                    NaN           2.86%  \n",
      "CRM     2020-08-31                                    NaN           2.82%  \n",
      "TRV     2009-06-08                                    NaN           3.62%  \n",
      "UNH     2012-09-24                                    NaN          10.29%  \n",
      "VZ      2004-04-08                                    NaN           0.73%  \n",
      "V       2013-09-20                                    NaN           4.16%  \n",
      "WBA     2018-06-26                                    NaN           0.79%  \n",
      "WMT     1997-03-17                                    NaN           2.94%  \n",
      "DIS     1991-05-06                                    NaN           1.89%  \n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "import time\n",
    "\n",
    "# Import the scraper class from the scraper module\n",
    "from scraper import Scraper\n",
    "\n",
    "# Set the URL that you want to scrape\n",
    "url = \"https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average\"\n",
    "\n",
    "# Set the API key\n",
    "api_key = \"83FRHS4AHOFR3RRT\"\n",
    "\n",
    "# Create a Scraper object\n",
    "scraper = Scraper(url, api_key)\n",
    "\n",
    "# Fetch the page\n",
    "soup = scraper.fetch_page()\n",
    "\n",
    "# Get the Table from Wikipedia\n",
    "df = scraper.parse_table(soup)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4fc50",
   "metadata": {},
   "source": [
    "This code attempts to retrieve data using the get_data method of the Scraper object. If the method is successful, the data is printed to the console. If there is an error, the error message is printed instead. The try and except blocks are used to handle potential errors that may occur when calling the get_data method. I cancelled the code, but you can try it and it will work (Change your Alpha Vantage API key, please!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b4cce9-c45a-4f8d-8830-096f84c7a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n",
      "C:\\Users\\valer\\Documents\\Scraper\\scraper.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(response, ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7356\\2265631189.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Scraper\\scraper.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;31m# Wait 12 seconds before making the next request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# Return the DataFrame containing the overview data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "try:\n",
    "    data = scraper.get_data()\n",
    "    print(data)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94a92fb-bcf7-4906-b587-464ce74d5a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Symbol': 'MMM',\n",
       " 'AssetType': 'Common Stock',\n",
       " 'Name': '3M Company',\n",
       " 'Description': 'The 3M Company is an American multinational conglomerate corporation operating in the fields of industry, worker safety, US health care, and consumer goods. The company produces over 60,000 products under several brands, including adhesives, abrasives, laminates, passive fire protection, personal protective equipment, window films, paint protection films, dental and orthodontic products, electrical and electronic connecting and insulating materials, medical products, car-care products, electronic circuits, healthcare software and optical films. It is based in Maplewood, a suburb of Saint Paul, Minnesota.',\n",
       " 'CIK': '66740',\n",
       " 'Exchange': 'NYSE',\n",
       " 'Currency': 'USD',\n",
       " 'Country': 'USA',\n",
       " 'Sector': 'LIFE SCIENCES',\n",
       " 'Industry': 'SURGICAL & MEDICAL INSTRUMENTS & APPARATUS',\n",
       " 'Address': '3M CENTER, BLDG. 220-13E-26A, ST PAUL, MN, US',\n",
       " 'FiscalYearEnd': 'December',\n",
       " 'LatestQuarter': '2022-09-30',\n",
       " 'MarketCapitalization': '69839077000',\n",
       " 'EBITDA': '6969000000',\n",
       " 'PERatio': '11.03',\n",
       " 'PEGRatio': '2.331',\n",
       " 'BookValue': '25.47',\n",
       " 'DividendPerShare': '5.95',\n",
       " 'DividendYield': '0.0478',\n",
       " 'EPS': '11.46',\n",
       " 'RevenuePerShareTTM': '60.79',\n",
       " 'ProfitMargin': '0.189',\n",
       " 'OperatingMarginTTM': '0.146',\n",
       " 'ReturnOnAssetsTTM': '0.0674',\n",
       " 'ReturnOnEquityTTM': '0.459',\n",
       " 'RevenueTTM': '34761998000',\n",
       " 'GrossProfitTTM': '16579000000',\n",
       " 'DilutedEPSTTM': '11.46',\n",
       " 'QuarterlyEarningsGrowthYOY': '1.763',\n",
       " 'QuarterlyRevenueGrowthYOY': '-0.036',\n",
       " 'AnalystTargetPrice': '128.71',\n",
       " 'TrailingPE': '11.03',\n",
       " 'ForwardPE': '12.0',\n",
       " 'PriceToSalesRatioTTM': '2.009',\n",
       " 'PriceToBookRatio': '4.985',\n",
       " 'EVToRevenue': '2.391',\n",
       " 'EVToEBITDA': '8.57',\n",
       " 'Beta': '1.005',\n",
       " '52WeekHigh': '174.39',\n",
       " '52WeekLow': '105.83',\n",
       " '50DayMovingAverage': '121.16',\n",
       " '200DayMovingAverage': '135.25',\n",
       " 'SharesOutstanding': '552743000',\n",
       " 'DividendDate': '2022-12-12',\n",
       " 'ExDividendDate': '2022-11-17'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper.get_overview(\"MMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eecc6e7-8d1b-472d-bb64-63aa06fbe2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Symbol', 'AssetType', 'Name', 'Description', 'CIK', 'Exchange',\n",
      "       'Currency', 'Country', 'Sector', 'Industry', 'Address', 'FiscalYearEnd',\n",
      "       'LatestQuarter', 'MarketCapitalization', 'EBITDA', 'PERatio',\n",
      "       'PEGRatio', 'BookValue', 'DividendPerShare', 'DividendYield', 'EPS',\n",
      "       'RevenuePerShareTTM', 'ProfitMargin', 'OperatingMarginTTM',\n",
      "       'ReturnOnAssetsTTM', 'ReturnOnEquityTTM', 'RevenueTTM',\n",
      "       'GrossProfitTTM', 'DilutedEPSTTM', 'QuarterlyEarningsGrowthYOY',\n",
      "       'QuarterlyRevenueGrowthYOY', 'AnalystTargetPrice', 'TrailingPE',\n",
      "       'ForwardPE', 'PriceToSalesRatioTTM', 'PriceToBookRatio', 'EVToRevenue',\n",
      "       'EVToEBITDA', 'Beta', '52WeekHigh', '52WeekLow', '50DayMovingAverage',\n",
      "       '200DayMovingAverage', 'SharesOutstanding', 'DividendDate',\n",
      "       'ExDividendDate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee8f6f5-74af-4675-b382-0c4c3249961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d82f9",
   "metadata": {},
   "source": [
    "This code defines a CSVReader class that has a read_csv method for reading the contents of a CSV file. When the method is called, it attempts to open the file at the specified file path and read its contents using the csv module. If the file is not found or there is an error reading the file, an error message is printed. The contents of each row in the CSV file are printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6103f425-adc3-4184-9f96-a41947a233f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class CSVReader:\n",
    "  def __init__(self, filepath):\n",
    "    self.filepath = filepath\n",
    "\n",
    "  def read_csv(self):\n",
    "    try:\n",
    "      with open(self.filepath, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "          print(row)\n",
    "    except FileNotFoundError:\n",
    "      print(f\"Error: The file at {self.filepath} could not be found.\")\n",
    "    except csv.Error:\n",
    "      print(f\"Error: An error occurred while reading the file at {self.filepath}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4edbedf6-b205-4957-ad85-4ac59aaea35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Company', 'Exchange', 'Industry', 'Date added', 'Notes', 'Index weighting']\n",
      "['MMM', '3M', 'NYSE', 'Conglomerate', '1976-08-09', 'As Minnesota Mining and Manufacturing', '2.41%']\n",
      "['AXP', 'American Express', 'NYSE', 'Financial services', '1982-08-30', '', '3.02%']\n",
      "['AMGN', 'Amgen', 'NASDAQ', 'Biopharmaceutical', '2020-08-31', '', '5.48%']\n",
      "['AAPL', 'Apple', 'NASDAQ', 'Information technology', '2015-03-19', '', '2.84%']\n",
      "['BA', 'Boeing', 'NYSE', 'Aerospace and defense', '1987-03-12', '', '3.36%']\n",
      "['CAT', 'Caterpillar', 'NYSE', 'Construction and Mining', '1991-05-06', '', '4.52%']\n",
      "['CVX', 'Chevron', 'NYSE', 'Petroleum industry', '2008-02-19', 'Also 1930-07-18 to 1999-11-01', '3.50%']\n",
      "['CSCO', 'Cisco', 'NASDAQ', 'Information technology', '2009-06-08', '', '0.96%']\n",
      "['KO', 'Coca-Cola', 'NYSE', 'Drink industry', '1987-03-12', 'Also 1932-05-26 to 1935-11-20', '1.22%']\n",
      "['DOW', 'Dow', 'NYSE', 'Chemical industry', '1991-05-06', '', '0.98%']\n",
      "['GS', 'Goldman Sachs', 'NYSE', 'Financial services', '2019-04-02', '', '7.36%']\n",
      "['HD', 'Home Depot', 'NYSE', 'Home Improvement', '1999-11-01', '', '6.27%']\n",
      "['HON', 'Honeywell', 'NASDAQ', 'Conglomerate', '2020-08-31', 'AlliedSignal and Honeywell', '4.17%']\n",
      "['INTC', 'Intel', 'NASDAQ', 'Semiconductor industry', '1999-11-01', '', '0.57%']\n",
      "['IBM', 'IBM', 'NYSE', 'Information technology', '1979-06-29', 'Also 1932-05-26 to 1939-03-04', '2.86%']\n",
      "['JNJ', 'Johnson & Johnson', 'NYSE', 'Pharmaceutical industry', '1997-03-17', '', '3.43%']\n",
      "['JPM', 'JPMorgan Chase', 'NYSE', 'Financial services', '1991-05-06', '', '2.61%']\n",
      "['MCD', \"McDonald's\", 'NYSE', 'Food industry', '1985-10-30', '', '5.24%']\n",
      "['MRK', 'Merck', 'NYSE', 'Pharmaceutical industry', '1979-06-29', '', '2.10%']\n",
      "['MSFT', 'Microsoft', 'NASDAQ', 'Information technology', '1999-11-01', '', '4.88%']\n",
      "['NKE', 'Nike', 'NYSE', 'Clothing industry', '2013-09-20', '', '2.13%']\n",
      "['PG', 'Procter & Gamble', 'NYSE', 'Fast-moving consumer goods', '1932-05-26', '', '2.86%']\n",
      "['CRM', 'Salesforce', 'NYSE', 'Information technology', '2020-08-31', '', '2.82%']\n",
      "['TRV', 'Travelers', 'NYSE', 'Insurance', '2009-06-08', '', '3.62%']\n",
      "['UNH', 'UnitedHealth', 'NYSE', 'Managed health care', '2012-09-24', '', '10.29%']\n",
      "['VZ', 'Verizon', 'NYSE', 'Telecommunications industry', '2004-04-08', '', '0.73%']\n",
      "['V', 'Visa', 'NYSE', 'Financial services', '2013-09-20', '', '4.16%']\n",
      "['WBA', 'Walgreens Boots Alliance', 'NASDAQ', 'Retailing', '2018-06-26', '', '0.79%']\n",
      "['WMT', 'Walmart', 'NYSE', 'Retailing', '1997-03-17', '', '2.94%']\n",
      "['DIS', 'Walt Disney Company', 'NYSE', 'Broadcasting and entertainment', '1991-05-06', '', '1.89%']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reader = CSVReader('data.csv')\n",
    "data = reader.read_csv()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ccfe7-775f-4133-aa0d-cd614d5e55b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5bcbc11-6ee4-4460-9f71-f0b28d60516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######     TO DO: MAKE COLUMNS NUMERICS AND SELECT STOCKS BASED ON MY THRESHOLDS IN THE FOLLOWING CODE\n",
    "######     THAT THRESHOLDS ARE WRONG, BUT I WILL USE THAT THs AS AN EXCERCISE. \n",
    "######     THE CORRECT WAY TO DO IT: CHANGE THE THRESHOLDS DEPENDING ON THE INDUSTRY, THE SECTOR, AND YOUR PREFERENCES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795c01f-d75b-499b-aab4-f00c30ffb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the thresholds for the market capitalization and earnings\n",
    "market_cap_threshold = 5e9\n",
    "earnings_threshold = 0\n",
    "\n",
    "# Set the thresholds for the P/E and P/B ratios\n",
    "pe_threshold = 15\n",
    "ps_threshold = 3\n",
    "pb_threshold = 1.5\n",
    "peg_threshold = 1\n",
    "\n",
    "# Set the threshold for the return on equity\n",
    "roe_threshold = 0.15\n",
    "\n",
    "# Set the threshold for the debt-to-equity ratio\n",
    "debt_equity_threshold = 1\n",
    "\n",
    "# Set the threshold for the current ratio\n",
    "current_ratio_threshold = 1\n",
    "\n",
    "# Identify undervalued stocks using the market capitalization, P/E and P/B ratios, and additional financial ratios\n",
    "undervalued_stocks = data[(data['MarketCapitalization'] < market_cap_threshold) & \n",
    "                          (data['QuarterlyEarningsGrowthYOY'] > earnings_threshold) & \n",
    "                          (data['50DayMovingAverage'] > data['200DayMovingAverage']) & \n",
    "                          (data[\"AnalystTargetPrice\"] > data['50DayMovingAverage']) & \n",
    "                          (data['PriceToSalesRatioTTM'] < ps_threshold) & \n",
    "                          (data['PEGRatio'] < peg_threshold) &\n",
    "                          (data['PERatio'] < pe_threshold) &\n",
    "                          (data['PriceToBookRatio'] < pb_threshold)]\n",
    "\n",
    "# Print the list of undervalued stocks\n",
    "#print('Undervalued stocks:')\n",
    "#print(undervalued_stocks)\n",
    "# Print the number of undervalued stocks\n",
    "#print('\\nNumber of undervalued stocks:', len(undervalued_stocks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
